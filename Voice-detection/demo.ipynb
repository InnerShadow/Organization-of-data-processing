{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2bcfb7-86ce-4bc8-a0ca-3f95490cf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models\n",
    "import turtle\n",
    "\n",
    "# Параметры записи аудио\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "FRAME_DURATION_MS = 30  # Длительность фрейма в миллисекундах\n",
    "PADDING_DURATION_MS = 300  # Длительность дополнительной оконной рамки в миллисекундах\n",
    "FRAME_SIZE = int(RATE * FRAME_DURATION_MS / 1000)  # Размер фрейма в сэмплах\n",
    "\n",
    "commands = ['down', 'go', 'left', 'right', 'stop', 'up']\n",
    "model = models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fade9670-7208-40cc-9046-434c2e3ace76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(waveform)\n",
    "    plt.title('Audio Waveform')\n",
    "    plt.xlabel('Time (samples)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c8e5a26-5e21-48f0-8bdf-62f08a2c81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audiobuffer(waveform):\n",
    "    waveform = waveform / 32768\n",
    "    waveform = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "    spectrogram = get_spectrogram(waveform)\n",
    "    spectrogram=tf.expand_dims(spectrogram, 0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ad6324-3e97-4069-83a3-1117986e5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "    input_len = 16000\n",
    "    waveform = waveform[:input_len]\n",
    "    zero_padding = tf.zeros(\n",
    "        [input_len] - tf.shape(waveform),\n",
    "        dtype=tf.float32)\n",
    "    waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    spectrogram = tf.signal.stft(\n",
    "        equal_length, frame_length=255, frame_step=128)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826af55b-5dd6-48d8-959c-5b6b6b679ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=FRAME_SIZE)\n",
    "    \n",
    "    print(\"Listening...\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(FRAME_SIZE)\n",
    "            yield np.frombuffer(data, dtype=np.int16)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    print(\"Recording stopped.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames):\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.tobytes(), sample_rate)\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = False\n",
    "                yield b''.join([f.tobytes() for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    if triggered:\n",
    "        yield b''.join([f.tobytes() for f in voiced_frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a75702-55e6-4afc-90a0-8187311946cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6975352f-f33a-41c5-a2f9-fb3a98c80121",
   "metadata": {},
   "outputs": [
    {
     "ename": "Terminator",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminator\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mturtle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetscreen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m t \u001b[38;5;241m=\u001b[39m turtle\u001b[38;5;241m.\u001b[39mTurtle() \u001b[38;5;66;03m# starts at right:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m size \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mturtlesize()\n",
      "File \u001b[0;32m<string>:5\u001b[0m, in \u001b[0;36mgetscreen\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTerminator\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s = turtle.getscreen()\n",
    "\n",
    "t = turtle.Turtle() # starts at right:\n",
    "\n",
    "size = t.turtlesize()\n",
    "increase = (2 * num for num in size)\n",
    "t.turtlesize(*increase)\n",
    "\n",
    "t.pensize(5)\n",
    "t.shapesize()\n",
    "t.pencolor(\"blue\")\n",
    "\n",
    "def go_right():\n",
    "    # target = 0\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        pass\n",
    "    elif current == 90:\n",
    "        t.right(90)\n",
    "    elif current == 180:\n",
    "        t.right(180)\n",
    "    elif current == 270:\n",
    "        t.left(90)\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "\n",
    "def go_up():\n",
    "    # target = 90\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        t.left(90)\n",
    "    elif current == 90:\n",
    "        pass\n",
    "    elif current == 180:\n",
    "        t.right(90)\n",
    "    elif current == 270:\n",
    "        t.left(180)\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "    \n",
    "def go_left():\n",
    "    # target = 180\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        t.left(180)\n",
    "    elif current == 90:\n",
    "        t.left(90)\n",
    "    elif current == 180:\n",
    "        pass\n",
    "    elif current == 270:\n",
    "        t.right(90)\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "    \n",
    "def go_down():\n",
    "    # target = 270\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        t.right(90)\n",
    "    elif current == 90:\n",
    "        t.right(180)\n",
    "    elif current == 180:\n",
    "        t.left(90)\n",
    "    elif current == 270:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "\n",
    "\n",
    "def move_turtle(command):\n",
    "    if command == 'up':\n",
    "        go_up()\n",
    "    elif command == 'down':\n",
    "        go_down()\n",
    "    elif command == 'left':\n",
    "        go_left()\n",
    "    elif command == 'right':\n",
    "        go_right()\n",
    "    elif command == 'go':\n",
    "        t.forward(100)\n",
    "    elif command == 'stop':\n",
    "        s.bye()\n",
    "        print('Stopping the turtle')\n",
    "\n",
    "\n",
    "# Создание экземпляра VAD\n",
    "vad = webrtcvad.Vad(3)  # Уровень агрессивности VAD (1-3)\n",
    "\n",
    "# Получение отрезков с командами\n",
    "audio_generator = record_audio()\n",
    "for audio_segment in vad_collector(RATE, FRAME_DURATION_MS, PADDING_DURATION_MS, vad, audio_generator):\n",
    "    print(\"Received audio segment with command:\", len(audio_segment))\n",
    "    waveform = np.frombuffer(audio_segment, dtype=np.int16)\n",
    "    plot_waveform(waveform)\n",
    "    spec = preprocess_audiobuffer(waveform)\n",
    "    prediction = model(spec)\n",
    "    print(prediction)\n",
    "    confidence = np.max(tf.nn.softmax(prediction))\n",
    "    print('Confidence: ', confidence)\n",
    "    # if confidence < 0.7:\n",
    "    #     print(\"Недостаточно уверенное предсказание. Пропускаем.\")\n",
    "    #     label_pred = np.argmax(prediction, axis=1)\n",
    "    #     print(label_pred)\n",
    "    #     command = commands[label_pred[0]]\n",
    "    #     print('Predicted label: ', command)\n",
    "    # else:\n",
    "    label_pred = np.argmax(prediction, axis=1)\n",
    "    print(label_pred)\n",
    "    command = commands[label_pred[0]]\n",
    "    print('Predicted label: ', command)\n",
    "    move_turtle(command)\n",
    "    if command == \"stop\":\n",
    "        # break\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce9789-b50c-46dd-9bf5-1d8e4c0163ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170be04-187d-4e9f-bcf2-ac0fc49f9861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42641f93-42d8-49f5-92f3-a1a5f3f422a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df20dc-00c7-4d5f-aa5f-6df518c0e535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a91eae-7481-4d63-9e1c-379abd6a41f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3578898-c3d3-4ac9-9d8d-04ac2eead7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52379fa3-f48e-4b25-92b6-e3b1235ba4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a361f6-cd23-4910-80e7-9d5b1e613c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a837d-c4b4-45e8-8613-886ef1036865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44594a8a-8906-4559-a132-2f94920e035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5174a-c45f-4279-8803-710750dd6dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
